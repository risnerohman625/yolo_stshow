import streamlit as st
import cv2
from PIL import Image
import numpy as np
import pandas as pd
import time
from datetime import datetime
import os
import torch
from torchvision import transforms
from torchvision.models import resnet18
from ultralytics import YOLO
from streamlit.components.v1 import html


# å®šä¹‰ä¿å­˜ç»“æœçš„å‡½æ•°
def save_result(defects, frame, manual=False):
    """ä¿å­˜æ£€æµ‹ç»“æœ"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{'manual' if manual else 'auto'}_capture_{timestamp}.jpg"
    save_path = os.path.join("data", filename)  # æŒ‡å®šä¿å­˜è·¯å¾„

    # ä¿å­˜å›¾ç‰‡
    cv2.imwrite(save_path, frame)

    # è®°å½•æ£€æµ‹ç»“æœ
    if defects:
        main_defect = max(defects, key=lambda x: x['confidence'])
        record = {
            "time": timestamp,
            "file": filename,
            "defect_type": main_defect['type'],
            "confidence": main_defect['confidence']
        }
    else:
        record = {
            "time": timestamp,
            "file": filename,
            "defect_type": "æ­£å¸¸",
            "confidence": 1.0
        }

    st.session_state.detection_history.append(record)
    st.toast(f"å·²ä¿å­˜æ£€æµ‹ç»“æœï¼š{filename}")


# ================== æ¨¡å‹åŠ è½½éƒ¨åˆ† ==================
@st.cache_resource
def load_models():
    """åŠ è½½é¢„è®­ç»ƒæ¨¡å‹"""
    # YOLOæ¨¡å‹
    yolo_model = YOLO(
        'C:\\Users\\14984\\Desktop\\exp\\runs\\detect\\defect_v8s\\weights\\best.pt'
    )  # ä¿®æ”¹ä¸ºå®é™…è·¯å¾„

    # CNNæ¨¡å‹
    cnn_model = resnet18(pretrained=False)
    cnn_model.fc = torch.nn.Linear(cnn_model.fc.in_features, 3)
    cnn_model.load_state_dict(torch.load('defect_cnn.pth', map_location='cpu'))
    cnn_model.eval()

    return yolo_model, cnn_model


# ================== æ ¸å¿ƒæ£€æµ‹å‡½æ•° ==================
def cnn_classify(crop_img):
    """CNNåˆ†ç±»å¤„ç†"""
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    img_tensor = transform(Image.fromarray(crop_img)).unsqueeze(0)
    with torch.no_grad():
        output = cnn_model(img_tensor)
    return CLASS_NAMES[torch.argmax(output).item()]


def yolo_detect(frame, conf_threshold):
    """YOLOæ£€æµ‹ä¸ç»“æœå¤„ç†"""
    results = yolo_model.predict(frame, conf=conf_threshold, verbose=False)[0]
    defects = []

    for box, cls, conf in zip(results.boxes.xyxy.cpu().numpy(),
                              results.boxes.cls.cpu().numpy().astype(int),
                              results.boxes.conf.cpu().numpy()):
        x1, y1, x2, y2 = map(int, box)
        label = results.names[cls]

        # è®°å½•æ£€æµ‹ç»“æœ
        defects.append({
            "type": label,
            "bbox": [x1, y1, x2, y2],
            "confidence": float(conf)
        })

        # å¯¹logoåŒºåŸŸè¿›è¡ŒCNNåˆ†ç±»
        if label == 'logo':
            crop = frame[y1:y2, x1:x2]
            if crop.size > 0:
                cnn_result = cnn_classify(cv2.cvtColor(crop,
                                                       cv2.COLOR_BGR2RGB))
                if cnn_result != 'normal':
                    defects.append({
                        "type": cnn_result,
                        "bbox": [x1, y1, x2, y2],
                        "confidence": 0.8
                    })

    return defects


# ================== å¯è§†åŒ–å‡½æ•° ==================
def draw_results(frame, defects):
    """ç»˜åˆ¶æ£€æµ‹ç»“æœ"""
    for defect in defects:
        x1, y1, x2, y2 = defect['bbox']
        label = defect['type']
        style = STYLE_CONFIG.get(label, STYLE_CONFIG['default'])

        # ç»˜åˆ¶è¾¹ç•Œæ¡†
        cv2.rectangle(frame, (x1, y1), (x2, y2), COLORS[label],
                      style['thickness'])

        # ç»˜åˆ¶æ ‡ç­¾
        (tw, th), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX,
                                      style['font_scale'],
                                      style['font_thickness'])
        # æ£€æŸ¥æ–‡å­—ä½ç½®æ˜¯å¦åœ¨è§†é¢‘ç”»é¢å†…
        if y1 - th - 5 < 0:
            y1 = th + 5
        if x1 + tw > frame.shape[1]:
            x1 = frame.shape[1] - tw

        cv2.rectangle(frame, (x1, y1 - th - 5), (x1 + tw, y1), COLORS[label],
                      -1)
        cv2.putText(frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX,
                    style['font_scale'], (255, 255, 255),
                    style['font_thickness'])
    return frame


# ================== Streamlitç•Œé¢ä¿®æ”¹éƒ¨åˆ† ==================
def add_space_key_listener():
    """æ·»åŠ ç©ºæ ¼é”®ç›‘å¬"""
    space_key_js = """
    <script>
    document.addEventListener('keydown', function(event) {
        if (event.code === 'Space') {
            window.parent.postMessage({'type':'streamlit:setComponentValue', 'value':'space_pressed'}, '*');
        }
    });
    </script>
    """
    html(space_key_js, height=0, width=0)


yolo_model, cnn_model = load_models()

# ================== æ£€æµ‹å‚æ•° ==================
CLASS_NAMES = ['dong', 'que', 'normal']
STYLE_CONFIG = {
    'logo': {
        'thickness': 4,
        'font_scale': 2.4,
        'font_thickness': 5
    },
    'default': {
        'thickness': 2,
        'font_scale': 0.8,
        'font_thickness': 2
    }
}
COLORS = {
    'logo': (255, 0, 0),  # çº¢è‰²
    'mao': (255, 165, 0),  # æ©™è‰²
    'dong': (0, 0, 255),  # è“è‰²
    'que': (0, 255, 0)  # ç»¿è‰²
}


# åˆå§‹åŒ–é¡µé¢
st.set_page_config(page_title="æ™ºèƒ½è´¨æ£€ç³»ç»Ÿ", page_icon="ğŸ”", layout="wide")
add_space_key_listener()

# åˆå§‹åŒ–sessionçŠ¶æ€
if 'detection_history' not in st.session_state:
    st.session_state.detection_history = []
if 'capture' not in st.session_state:
    st.session_state.capture = False

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.header("ç³»ç»Ÿé…ç½®")
    detection_mode = st.radio("æ£€æµ‹æ¨¡å¼", ["å®æ—¶æ‘„åƒå¤´", "ä¸Šä¼ å›¾ç‰‡"])
    confidence_threshold = st.slider("ç½®ä¿¡åº¦é˜ˆå€¼", 0.0, 1.0, 0.5, 0.01)
    auto_save = st.checkbox("è‡ªåŠ¨ä¿å­˜æ£€æµ‹ç»“æœ", False)  # é»˜è®¤å…³é—­è‡ªåŠ¨ä¿å­˜
    manual_save = st.checkbox("å¯ç”¨ç©ºæ ¼é”®æ‰‹åŠ¨ä¿å­˜", True)

# ä¸»ç•Œé¢
st.title("æ™ºèƒ½è´¨æ£€ç³»ç»Ÿ")
col1, col2 = st.columns(2)

with col1:
    st.subheader("åŸè§†é¢‘ç”»é¢")
    original_camera_feed = st.empty()

with col2:
    st.subheader("æ£€æµ‹åè§†é¢‘ç”»é¢")
    detected_camera_feed = st.empty()

if detection_mode == "å®æ—¶æ‘„åƒå¤´":
    start_btn = st.button("å¼€å§‹æ£€æµ‹")
    stop_btn = st.button("åœæ­¢æ£€æµ‹")
    save_btn = st.button("ä¿å­˜å½“å‰å›¾ç‰‡")  # æ·»åŠ ä¿å­˜æŒ‰é’®

    if start_btn:
        st.session_state.capture = True
        cap = cv2.VideoCapture(1)  # æ ¹æ®æ‘„åƒå¤´è°ƒæ•´ç¼–å·

    if stop_btn:
        st.session_state.capture = False
        if 'cap' in locals():
            cap.release()

    if st.session_state.capture:
        while st.session_state.capture:
            ret, frame = cap.read()
            if not ret:
                st.error("æ‘„åƒå¤´è¿æ¥å¤±è´¥")
                break

            original_frame = frame.copy()  # ä¿å­˜åŸè§†é¢‘å¸§

            # æ‰§è¡Œæ£€æµ‹
            defects = yolo_detect(frame, confidence_threshold)
            detected_frame = draw_results(frame.copy(), defects)

            # æ˜¾ç¤ºåŸè§†é¢‘å’Œæ£€æµ‹åè§†é¢‘
            original_camera_feed.image(cv2.cvtColor(original_frame,
                                                    cv2.COLOR_BGR2RGB),
                                       channels="RGB")
            detected_camera_feed.image(cv2.cvtColor(detected_frame,
                                                    cv2.COLOR_BGR2RGB),
                                       channels="RGB")

            # ä¿å­˜é€»è¾‘
            if auto_save:
                save_result(defects, detected_frame)

            # æ‰‹åŠ¨ä¿å­˜å¤„ç†
            if manual_save and (st.session_state.get('space_pressed')
                                or save_btn):
                save_result(defects, detected_frame, manual=True)
                st.session_state.space_pressed = False

elif detection_mode == "ä¸Šä¼ å›¾ç‰‡":
    uploaded_file = st.file_uploader("ä¸Šä¼ æ£€æµ‹å›¾ç‰‡",
                                     type=["jpg", "png", "jpeg", "bmp"])
    if uploaded_file is not None:
        image = Image.open(uploaded_file)
        frame = np.array(image.convert('RGB'))

        original_frame = frame.copy()  # ä¿å­˜åŸè§†é¢‘å¸§

        # æ‰§è¡Œæ£€æµ‹
        defects = yolo_detect(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR),
                              confidence_threshold)
        detected_frame = draw_results(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR),
                                      defects)

        # æ˜¾ç¤ºåŸè§†é¢‘å’Œæ£€æµ‹åè§†é¢‘
        col1.image(cv2.cvtColor(original_frame, cv2.COLOR_BGR2RGB),
                   caption="åŸå›¾ç‰‡",
                   use_container_width=True)
        col2.image(cv2.cvtColor(detected_frame, cv2.COLOR_BGR2RGB),
                   caption="æ£€æµ‹åå›¾ç‰‡",
                   use_container_width=True)

        # è‡ªåŠ¨ä¿å­˜
        if auto_save:
            save_result(defects, detected_frame)

        # æ‰‹åŠ¨ä¿å­˜å¤„ç†
        if manual_save and st.button("ä¿å­˜å½“å‰å›¾ç‰‡"):
            save_result(defects, detected_frame, manual=True)

# æ£€æµ‹ç»“æœç»Ÿè®¡
with st.expander("æ£€æµ‹ç»“æœç»Ÿè®¡"):
    # å®æ—¶ç»Ÿè®¡
    if st.session_state.detection_history:
        latest = st.session_state.detection_history[-1]
        st.metric("æœ€æ–°ç¼ºé™·ç±»å‹", latest['defect_type'])
        st.metric("ç½®ä¿¡åº¦", f"{latest['confidence'] * 100:.1f}%")
    else:
        st.warning("ç­‰å¾…æ£€æµ‹æ•°æ®...")

    # å†å²è®°å½•
    if st.session_state.detection_history:
        st.dataframe(pd.DataFrame(st.session_state.detection_history))
    else:
        st.info("æš‚æ— å†å²è®°å½•")

# åˆ›å»ºæ•°æ®ç›®å½•
os.makedirs("data", exist_ok=True)

