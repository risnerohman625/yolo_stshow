import os
import time
import streamlit as st
import cv2
from PIL import Image
import numpy as np
import pandas as pd
from datetime import datetime
import torch
from torchvision import transforms
from torchvision.models import resnet18
from ultralytics import YOLO
from streamlit.components.v1 import html
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase, WebRtcMode
import av

# ================== å…¨å±€é…ç½® ==================
CLASS_NAMES = ['dong', 'que', 'normal']
STYLE_CONFIG = {
    'logo':   {'thickness': 4, 'font_scale': 2.4, 'font_thickness': 5},
    'default':{'thickness': 2, 'font_scale': 0.8, 'font_thickness': 2},
}
COLORS = {
    'logo': (255,0,0), 'mao': (255,165,0),
    'dong': (0,0,255), 'que': (0,255,0),
}

# ================== åŠ¨æ€è·¯å¾„ ==================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
MODEL_DIR = os.path.join(BASE_DIR, "models")
YOLO_PATH = os.path.join(MODEL_DIR, "best.pt")
CNN_PATH  = os.path.join(MODEL_DIR, "defect_cnn.pth")

# ================== åŠ è½½æ¨¡å‹ ==================
@st.cache_resource
def load_models():
    if not os.path.exists(YOLO_PATH):
        st.error(f"æœªæ‰¾åˆ° YOLO æ¨¡å‹ï¼š{YOLO_PATH}")
    if not os.path.exists(CNN_PATH):
        st.error(f"æœªæ‰¾åˆ° CNN æ¨¡å‹ï¼š{CNN_PATH}")
    yolo = YOLO(YOLO_PATH)
    cnn = resnet18(pretrained=False)
    cnn.fc = torch.nn.Linear(cnn.fc.in_features, len(CLASS_NAMES))
    cnn.load_state_dict(torch.load(CNN_PATH, map_location="cpu"))
    cnn.eval()
    return yolo, cnn

yolo_model, cnn_model = load_models()

# ================== ä¿å­˜ç»“æœ ==================
def save_result(defects, frame, manual=False):
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    fn = f"{'manual' if manual else 'auto'}_capture_{ts}.jpg"
    os.makedirs("data", exist_ok=True)
    path = os.path.join("data", fn)
    cv2.imwrite(path, frame)
    if defects:
        m = max(defects, key=lambda d: d['confidence'])
        rec = {"time":ts,"file":fn,
               "defect_type":m['type'],"confidence":m['confidence']}
    else:
        rec = {"time":ts,"file":fn,"defect_type":"æ­£å¸¸","confidence":1.0}
    st.session_state.detection_history.append(rec)
    st.toast(f"å·²ä¿å­˜æ£€æµ‹ç»“æœï¼š{fn}")

# ================== æ£€æµ‹é€»è¾‘ ==================
def cnn_classify(crop):
    tf = transforms.Compose([
        transforms.Resize((224,224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),
    ])
    x = tf(Image.fromarray(crop)).unsqueeze(0)
    with torch.no_grad():
        out = cnn_model(x)
    return CLASS_NAMES[int(out.argmax())]

def yolo_detect(frame, conf):
    res = yolo_model.predict(frame, conf=conf, verbose=False)[0]
    defects = []
    for box, cls, cf in zip(res.boxes.xyxy.cpu().numpy(),
                             res.boxes.cls.cpu().numpy().astype(int),
                             res.boxes.conf.cpu().numpy()):
        x1,y1,x2,y2 = map(int, box)
        lbl = res.names[cls]
        defects.append({"type":lbl,"bbox":[x1,y1,x2,y2],"confidence":float(cf)})
        if lbl=="logo":
            crop = frame[y1:y2,x1:x2]
            if crop.size>0:
                sub = cnn_classify(cv2.cvtColor(crop,cv2.COLOR_BGR2RGB))
                if sub!="normal":
                    defects.append({"type":sub,"bbox":[x1,y1,x2,y2],"confidence":0.8})
    return defects

def draw_results(frame, defects):
    for d in defects:
        x1,y1,x2,y2 = d['bbox']; lab=d['type']
        s = STYLE_CONFIG.get(lab,STYLE_CONFIG['default'])
        cv2.rectangle(frame,(x1,y1),(x2,y2), COLORS[lab], s['thickness'])
        (tw,th),_ = cv2.getTextSize(lab, cv2.FONT_HERSHEY_SIMPLEX,
                                   s['font_scale'], s['font_thickness'])
        yy = max(th+5, y1)
        cv2.rectangle(frame,(x1,yy-th-5),(x1+tw,yy), COLORS[lab], -1)
        cv2.putText(frame, lab, (x1,yy-5),
                    cv2.FONT_HERSHEY_SIMPLEX, s['font_scale'],
                    (255,255,255), s['font_thickness'])
    return frame

# ================== webrtc å¤„ç†å™¨ ==================
class YoloProcessor(VideoProcessorBase):
    def __init__(self, conf): self.conf=conf
    def recv(self, frame):
        img = frame.to_ndarray(format="bgr24")
        det = yolo_detect(img, self.conf)
        out = draw_results(img.copy(), det)
        return av.VideoFrame.from_ndarray(out, format="bgr24")

# ================== ç©ºæ ¼ç›‘å¬ ==================
def add_space_listener():
    js = """
    <script>
      document.addEventListener('keydown', e=>{
        if(e.code==='Space'){
          window.parent.postMessage(
            {type:'streamlit:setComponentValue',value:'space_pressed'},'*');
        }
      });
    </script>
    """
    html(js, height=0, width=0)

# ================== ä¸»ç•Œé¢ ==================
st.set_page_config("æ™ºèƒ½è´¨æ£€ç³»ç»Ÿ","ğŸ”",layout="wide")
add_space_listener()
os.makedirs("data", exist_ok=True)
st.session_state.setdefault("detection_history", [])

with st.sidebar:
    st.header("ç³»ç»Ÿé…ç½®")
    mode = st.radio("æ£€æµ‹æ¨¡å¼", ["å®æ—¶æ‘„åƒå¤´","ä¸Šä¼ å›¾ç‰‡","ä¸Šä¼ è§†é¢‘"])
    conf = st.slider("ç½®ä¿¡åº¦é˜ˆå€¼", 0.0, 1.0, 0.5, 0.01)
    auto = st.checkbox("è‡ªåŠ¨ä¿å­˜æ£€æµ‹ç»“æœ", False)
    manual = st.checkbox("ç©ºæ ¼é”®æ‰‹åŠ¨ä¿å­˜", True)

st.title("ğŸ” æ™ºèƒ½è´¨æ£€ç³»ç»Ÿ")
c1,c2 = st.columns(2)
orig = c1.empty(); det = c2.empty()

if mode=="å®æ—¶æ‘„åƒå¤´":
    webrtc_streamer(
        key="yolo",
        mode=WebRtcMode.SENDRECV,
        video_processor_factory=lambda: YoloProcessor(conf),
        async_processing=True,
    )
    st.info("è¯·æˆæƒæµè§ˆå™¨è®¿é—®æ‘„åƒå¤´")

elif mode=="ä¸Šä¼ å›¾ç‰‡":
    up = st.file_uploader("ä¸Šä¼ æ£€æµ‹å›¾ç‰‡", type=["jpg","png","jpeg","bmp"])
    if up:
        img = np.array(Image.open(up).convert("RGB"))
        dets = yolo_detect(cv2.cvtColor(img,cv2.COLOR_RGB2BGR),conf)
        out = draw_results(cv2.cvtColor(img,cv2.COLOR_RGB2BGR),dets)
        orig.image(img,use_column_width=True,caption="åŸå›¾")
        det.image(cv2.cvtColor(out,cv2.COLOR_BGR2RGB),
                  use_column_width=True,caption="æ£€æµ‹ç»“æœ")
        if auto:    save_result(dets,out)
        if manual and st.button("ä¿å­˜å½“å‰å›¾ç‰‡"):
            save_result(dets,out,manual=True)

elif mode=="ä¸Šä¼ è§†é¢‘":
    vid = st.file_uploader("ä¸Šä¼ æ£€æµ‹è§†é¢‘", type=["mp4","avi"])
    if vid:
        tmp="temp.mp4"
        with open(tmp,"wb") as f: f.write(vid.read())
        cap=cv2.VideoCapture(tmp)
        st.session_state.setdefault("playing",False)
        if st.button("æ’­æ”¾/æš‚åœ"):
            st.session_state.playing = not st.session_state.playing
        while st.session_state.playing and cap.isOpened():
            ret,frm = cap.read()
            if not ret: break
            dets=yolo_detect(frm,conf)
            out = draw_results(frm.copy(),dets)
            orig.image(cv2.cvtColor(frm,cv2.COLOR_BGR2RGB),
                       use_column_width=True)
            det.image(cv2.cvtColor(out,cv2.COLOR_BGR2RGB),
                      use_column_width=True)
            if auto: save_result(dets,out)
            if manual and st.button("ä¿å­˜å¸§"):
                save_result(dets,out,manual=True)
        cap.release(); os.remove(tmp)

with st.expander("æ£€æµ‹ç»“æœç»Ÿè®¡"):
    if st.session_state.detection_history:
        last = st.session_state.detection_history[-1]
        st.metric("æœ€æ–°ç¼ºé™·ç±»å‹", last['defect_type'])
        st.metric("ç½®ä¿¡åº¦", f"{last['confidence']*100:.1f}%")
        st.dataframe(pd.DataFrame(st.session_state.detection_history),
                     use_container_width=True)
    else:
        st.info("æš‚æ— æ£€æµ‹æ•°æ®")
