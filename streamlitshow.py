import os
import time
import threading
from queue import Queue
from datetime import datetime
from io import BytesIO

import streamlit as st
import numpy as np
import pandas as pd
import cv2
from PIL import Image
import av
from streamlit.components.v1 import html
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase, WebRtcMode

import torch
from torchvision import transforms
from torchvision.models import resnet18
from ultralytics import YOLO
import mss

# ================== å…¨å±€é…ç½® ==================
CLASS_NAMES = ['dong', 'que', 'normal']
COLORS = {
    'logo': (255, 0, 0),
    'mao': (255, 165, 0),
    'dong': (0, 0, 255),
    'que': (0, 255, 0)
}
STYLE_CONFIG = {
    'logo': {'thickness': 4, 'font_scale': 2.4, 'font_thickness': 5},
    'default': {'thickness': 2, 'font_scale': 0.8, 'font_thickness': 2}
}

# ================== è·¯å¾„ä¸æ¨¡å‹åŠ è½½ ==================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
MODELS_DIR = os.path.join(BASE_DIR, "models")
YOLO_PATH = os.path.join(MODELS_DIR, "best.pt")
CNN_PATH = os.path.join(MODELS_DIR, "defect_cnn.pth")

@st.cache_resource
def load_models():
    # åŠ¨æ€æ‰¾æ–‡ä»¶
    if not os.path.exists(YOLO_PATH) or not os.path.exists(CNN_PATH):
        st.error("è¯·ç¡®ä¿ models/best.pt å’Œ models/defect_cnn.pth å·²ä¸Šä¼ åˆ°ä»“åº“ models/ ç›®å½•ä¸‹")
    yolo_model = YOLO(YOLO_PATH)
    cnn_model = resnet18(pretrained=False)
    cnn_model.fc = torch.nn.Linear(cnn_model.fc.in_features, len(CLASS_NAMES))
    cnn_model.load_state_dict(torch.load(CNN_PATH, map_location='cpu'))
    cnn_model.eval()
    return yolo_model, cnn_model

yolo_model, cnn_model = load_models()

# ================== æ£€æµ‹ä¸ç»˜å›¾ ==================
def cnn_classify(crop_img):
    tf = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),
    ])
    x = tf(Image.fromarray(crop_img)).unsqueeze(0)
    with torch.no_grad():
        out = cnn_model(x)
    return CLASS_NAMES[int(torch.argmax(out))]

def yolo_detect(frame, conf_thresh):
    results = yolo_model.predict(frame, conf=conf_thresh, verbose=False)[0]
    defects = []
    for box, cls, conf in zip(results.boxes.xyxy.cpu().numpy(),
                              results.boxes.cls.cpu().numpy().astype(int),
                              results.boxes.conf.cpu().numpy()):
        x1,y1,x2,y2 = map(int,box)
        label = results.names[cls]
        defects.append({"type":label,"bbox":[x1,y1,x2,y2],"confidence":float(conf)})
        if label=='logo':
            crop = frame[y1:y2, x1:x2]
            if crop.size:
                sub = cnn_classify(cv2.cvtColor(crop,cv2.COLOR_BGR2RGB))
                if sub!='normal':
                    defects.append({"type":sub,"bbox":[x1,y1,x2,y2],"confidence":0.8})
    return defects

def draw_results(frame, defects):
    for d in defects:
        x1,y1,x2,y2 = d['bbox']
        style = STYLE_CONFIG.get(d['type'], STYLE_CONFIG['default'])
        cv2.rectangle(frame,(x1,y1),(x2,y2),COLORS[d['type']],style['thickness'])
        (tw,th),_ = cv2.getTextSize(d['type'], cv2.FONT_HERSHEY_SIMPLEX,
                                    style['font_scale'], style['font_thickness'])
        cv2.rectangle(frame,(x1,y1-th-5),(x1+tw,y1),COLORS[d['type']],-1)
        cv2.putText(frame,d['type'],(x1,y1-5),
                    cv2.FONT_HERSHEY_SIMPLEX, style['font_scale'],
                    (255,255,255), style['font_thickness'])
    return frame

# ================== ä¿å­˜ç»“æœ ==================
def save_result(defects, frame, manual=False):
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    fn = f"{'manual' if manual else 'auto'}_{ts}.jpg"
    os.makedirs("data", exist_ok=True)
    path = os.path.join("data", fn)
    cv2.imwrite(path, frame)
    rec = {
        "time": ts,
        "file": fn,
        "defect_type": max(defects, key=lambda x:x['confidence'])['type'] if defects else "normal",
        "confidence": max([d['confidence'] for d in defects], default=1.0)
    }
    st.session_state.history.append(rec)

# ================== WebRTC å¤„ç†å™¨ ==================
class YoloProcessor(VideoProcessorBase):
    def __init__(self, conf_threshold):
        self.conf = conf_threshold
    def recv(self, frame):
        img = frame.to_ndarray(format="bgr24")
        defects = yolo_detect(img, self.conf)
        out = draw_results(img.copy(), defects)
        return av.VideoFrame.from_ndarray(out, format="bgr24")

# ================== å±å¹•æ•è·çº¿ç¨‹ ==================
frame_q = Queue(1)
det_q = Queue(1)
stop_flag = threading.Event()

def screen_thread(conf, fps, region):
    with mss.mss() as sct:
        while not stop_flag.is_set():
            shot = np.array(sct.grab(region))
            img = cv2.cvtColor(shot,cv2.COLOR_BGRA2BGR)
            det = yolo_detect(img, conf)
            out = draw_results(img.copy(), det)
            if frame_q.full(): frame_q.get_nowait()
            if det_q.full(): det_q.get_nowait()
            frame_q.put(img); det_q.put(out)
            time.sleep(1/fps)

# ================== Streamlit UI ==================
def main():
    st.set_page_config("æ™ºèƒ½è´¨æ£€ç³»ç»Ÿ", "ğŸ”", layout="wide")
    # åˆå§‹åŒ– state
    st.session_state.setdefault("history", [])
    st.sidebar.header("è®¾ç½®")
    mode = st.sidebar.radio("æ¨¡å¼", ["æ‘„åƒå¤´(webrtc)", "ä¸Šä¼ å›¾ç‰‡", "ä¸Šä¼ è§†é¢‘", "å±å¹•æ•è·"])
    conf = st.sidebar.slider("ç½®ä¿¡åº¦",0.0,1.0,0.5,0.01)
    auto = st.sidebar.checkbox("è‡ªåŠ¨ä¿å­˜", False)
    manual = st.sidebar.checkbox("ç©ºæ ¼æ‰‹åŠ¨ä¿å­˜", True)

    st.title("ğŸ” æ™ºèƒ½è´¨æ£€ç³»ç»Ÿ")
    col1,col2 = st.columns(2)
    orig = col1.empty(); det = col2.empty()

    if mode=="æ‘„åƒå¤´(webrtc)":
        webrtc_streamer(
            key="yolo",
            mode=WebRtcMode.SENDRECV,
            video_processor_factory=lambda: YoloProcessor(conf),
            async_processing=True
        )
        st.info("è¯·æˆæƒæµè§ˆå™¨ä½¿ç”¨æ‘„åƒå¤´")
    elif mode=="ä¸Šä¼ å›¾ç‰‡":
        f = st.file_uploader("å›¾ç‰‡", type=["jpg","png","jpeg"])
        if f:
            img = np.array(Image.open(f).convert("RGB"))
            d = yolo_detect(cv2.cvtColor(img,cv2.COLOR_RGB2BGR),conf)
            out = draw_results(cv2.cvtColor(img,cv2.COLOR_RGB2BGR),d)
            orig.image(img,use_column_width=True)
            det.image(cv2.cvtColor(out,cv2.COLOR_BGR2RGB),use_column_width=True)
            if auto: save_result(d,out)
            if manual and st.button("ä¿å­˜å›¾ç‰‡"): save_result(d,out,True)
    elif mode=="ä¸Šä¼ è§†é¢‘":
        f = st.file_uploader("è§†é¢‘", type=["mp4","avi"])
        if f:
            tmp="temp.mp4"
            with open(tmp,"wb") as o: o.write(f.read())
            cap = cv2.VideoCapture(tmp)
            play = st.button("æ’­æ”¾")
            if play:
                while cap.isOpened():
                    ret,frm=cap.read()
                    if not ret: break
                    d=yolo_detect(frm,conf)
                    o=draw_results(frm.copy(),d)
                    orig.image(cv2.cvtColor(frm,cv2.COLOR_BGR2RGB),use_column_width=True)
                    det.image(cv2.cvtColor(o,cv2.COLOR_BGR2RGB),use_column_width=True)
                    if auto: save_result(d,o)
                    if manual and st.button("ä¿å­˜å¸§"): save_result(d,o,True)
                cap.release()
                os.remove(tmp)
    else:  # å±å¹•æ•è·
        fps = st.sidebar.slider("FPS",1,30,10)
        region = {
            "top":st.sidebar.number_input("Top",0,10000,100),
            "left":st.sidebar.number_input("Left",0,10000,100),
            "width":st.sidebar.number_input("W",100,2000,800),
            "height":st.sidebar.number_input("H",100,2000,600),
        }
        if st.button("å¼€å§‹æ•è·"):
            stop_flag.clear()
            threading.Thread(target=screen_thread, args=(conf,fps,region), daemon=True).start()
        if st.button("åœæ­¢æ•è·"):
            stop_flag.set()
        if not frame_q.empty():
            orig.image(cv2.cvtColor(frame_q.get(),cv2.COLOR_BGR2RGB),use_column_width=True)
        if not det_q.empty():
            img=det_q.get()
            det.image(cv2.cvtColor(img,cv2.COLOR_BGR2RGB),use_column_width=True)
            if auto: save_result(yolo_detect(img,conf),img)
            if manual and st.button("ä¿å­˜å¸§"): save_result(yolo_detect(img,conf),img,True)

    # å†å²è®°å½•
    with st.expander("ğŸ”– æ£€æµ‹å†å²"):
        if st.session_state.history:
            df = pd.DataFrame(st.session_state.history)
            st.dataframe(df)
            if st.button("å¯¼å‡ºExcel"):
                buf=BytesIO()
                with pd.ExcelWriter(buf, engine="xlsxwriter") as w:
                    df.to_excel(w,index=False)
                b64 = base64.b64encode(buf.getvalue()).decode()
                href = f'<a href="data:application/vnd.openxmlformats-officedocument.spreadsheetml.sheet;base64,{b64}" download="history.xlsx">ä¸‹è½½</a>'
                st.markdown(href, unsafe_allow_html=True)
        else:
            st.info("æš‚æ— è®°å½•")

if __name__=="__main__":
    main()
