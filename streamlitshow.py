# streamlitshow.py

import os
import time
from datetime import datetime

import cv2
import numpy as np
import pandas as pd
import streamlit as st  # å¼•å…¥ Streamlit
from PIL import Image
import torch
from torchvision import transforms
from torchvision.models import resnet18
from ultralytics import YOLO
from streamlit.components.v1 import html

# ================== Streamlit é¡µé¢é…ç½®ï¼ˆå¿…é¡»æœ€å…ˆè°ƒç”¨ï¼‰ ==================
st.set_page_config(page_title="æ™ºèƒ½è´¨æ£€ç³»ç»Ÿ", page_icon="ğŸ”", layout="wide")

# ================== ä¿å­˜ç»“æœ ==================
def save_result(defects, frame, manual=False):
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{'manual' if manual else 'auto'}_capture_{timestamp}.jpg"
    os.makedirs("data", exist_ok=True)
    save_path = os.path.join("data", filename)
    cv2.imwrite(save_path, frame)

    if defects:
        main_defect = max(defects, key=lambda x: x["confidence"])
        record = {
            "time": timestamp,
            "file": filename,
            "defect_type": main_defect["type"],
            "confidence": main_defect["confidence"],
        }
    else:
        record = {
            "time": timestamp,
            "file": filename,
            "defect_type": "normal",
            "confidence": 1.0,
        }
    st.session_state.detection_history.append(record)
    st.toast(f"å·²ä¿å­˜ï¼š{filename}")

# ================== æ¨¡å‹åŠ è½½ ==================
@st.cache_resource
def load_models():
    # YOLO æ£€æµ‹æ¨¡å‹
    yolo_model = YOLO("./runs/detect/defect_v8s/weights/best.pt")
    # CNN ç»†åˆ†ç±»æ¨¡å‹
    cnn_model = resnet18(pretrained=False)
    cnn_model.fc = torch.nn.Linear(cnn_model.fc.in_features, 3)
    cnn_model.load_state_dict(torch.load("defect_cnn.pth", map_location="cpu"))
    cnn_model.eval()
    return yolo_model, cnn_model

yolo_model, cnn_model = load_models()

# ================== æ ¸å¿ƒæ£€æµ‹ ==================
CLASS_NAMES = ["dong", "que", "normal"]

def cnn_classify(crop_img):
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406],
                             [0.229, 0.224, 0.225]),
    ])
    img_t = transform(Image.fromarray(crop_img)).unsqueeze(0)
    with torch.no_grad():
        out = cnn_model(img_t)
    return CLASS_NAMES[int(out.argmax())]

def yolo_detect(frame, conf_threshold):
    res = yolo_model.predict(frame, conf=conf_threshold, verbose=False)[0]
    defects = []
    for box, cls_idx, conf in zip(
        res.boxes.xyxy.cpu().numpy(),
        res.boxes.cls.cpu().numpy().astype(int),
        res.boxes.conf.cpu().numpy()
    ):
        x1, y1, x2, y2 = map(int, box)
        label = res.names[cls_idx]
        defects.append({
            "type": label,
            "bbox": [x1, y1, x2, y2],
            "confidence": float(conf)
        })
        # å¯¹ logo å†è·‘ä¸€æ¬¡ CNN ç»†åˆ†ç±»
        if label == "logo":
            crop = frame[y1:y2, x1:x2]
            if crop.size:
                cnn_rst = cnn_classify(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))
                if cnn_rst != "normal":
                    defects.append({
                        "type": cnn_rst,
                        "bbox": [x1, y1, x2, y2],
                        "confidence": 0.8
                    })
    return defects

# ================== å¯è§†åŒ– ==================
STYLE_CONFIG = {
    "logo":    {"thickness": 4, "font_scale": 2.4, "font_thickness": 5},
    "default": {"thickness": 2, "font_scale": 0.8, "font_thickness": 2},
}
COLORS = {
    "logo": (255, 0, 0),
    "mao":  (255, 165, 0),
    "dong": (0, 0, 255),
    "que":  (0, 255, 0),
}

def draw_results(frame, defects):
    for d in defects:
        x1, y1, x2, y2 = d["bbox"]
        style = STYLE_CONFIG.get(d["type"], STYLE_CONFIG["default"])
        color = COLORS.get(d["type"], (255, 255, 255))
        cv2.rectangle(frame, (x1, y1), (x2, y2), color, style["thickness"])
        (tw, th), _ = cv2.getTextSize(d["type"],
                                      cv2.FONT_HERSHEY_SIMPLEX,
                                      style["font_scale"],
                                      style["font_thickness"])
        yy = max(th + 5, y1)
        xx = min(frame.shape[1] - tw, x1)
        cv2.rectangle(frame,
                      (xx, yy - th - 5),
                      (xx + tw, yy),
                      color,
                      -1)
        cv2.putText(frame,
                    d["type"],
                    (xx, yy - 5),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    style["font_scale"],
                    (255, 255, 255),
                    style["font_thickness"])
    return frame

# ç©ºæ ¼é”®ç›‘å¬
def add_space_key_listener():
    js = """
    <script>
    document.addEventListener('keydown', e => {
      if (e.code==='Space') {
        window.parent.postMessage(
          {type:'streamlit:setComponentValue', value:'space_pressed'}, '*'
        )
      }
    });
    </script>
    """
    html(js, height=0)

add_space_key_listener()

# ================== Streamlit UI ==================
# åˆå§‹åŒ– session_state
st.session_state.setdefault("detection_history", [])
st.session_state.setdefault("video_playing", False)
st.session_state.setdefault("space_pressed", None)

with st.sidebar:
    st.header("ç³»ç»Ÿé…ç½®")
    mode = st.radio("æ£€æµ‹æ¨¡å¼", ["å®æ—¶æ‘„åƒå¤´", "ä¸Šä¼ å›¾ç‰‡", "ä¸Šä¼ è§†é¢‘"])
    conf_th = st.slider("ç½®ä¿¡åº¦é˜ˆå€¼", 0.0, 1.0, 0.5, 0.01)
    auto_save = st.checkbox("è‡ªåŠ¨ä¿å­˜", False)
    manual_save = st.checkbox("ç©ºæ ¼æ‰‹åŠ¨ä¿å­˜", True)

col1, col2 = st.columns(2)
with col1:
    st.subheader("åŸç”»é¢")
    orig_disp = st.empty()
with col2:
    st.subheader("æ£€æµ‹å")
    det_disp = st.empty()

# â€”â€”â€”â€” ä¸»æµç¨‹ â€”â€”â€”â€”
if mode == "å®æ—¶æ‘„åƒå¤´":
    cap = cv2.VideoCapture(0)
    st.session_state.video_playing = True
    while st.session_state.video_playing:
        ret, frame = cap.read()
        if not ret:
            break
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        defects = yolo_detect(frame, conf_th)
        vis = draw_results(frame.copy(), defects)
        orig_disp.image(frame, channels="RGB")
        det_disp.image(vis, channels="RGB")
        if auto_save:
            save_result(defects, cv2.cvtColor(vis, cv2.COLOR_RGB2BGR))
        if manual_save and st.session_state.space_pressed == "space_pressed":
            save_result(defects, cv2.cvtColor(vis, cv2.COLOR_RGB2BGR), manual=True)
            st.session_state.space_pressed = None
        time.sleep(0.03)
    cap.release()

elif mode == "ä¸Šä¼ å›¾ç‰‡":
    uploaded = st.file_uploader("ä¸Šä¼ å›¾ç‰‡", type=["jpg", "png", "jpeg"])
    if uploaded:
        img = np.array(Image.open(uploaded).convert("RGB"))
        orig_disp.image(img, channels="RGB")
        defects = yolo_detect(img, conf_th)
        vis = draw_results(img.copy(), defects)
        det_disp.image(vis, channels="RGB")
        if st.button("ä¿å­˜å½“å‰"):
            save_result(defects, cv2.cvtColor(vis, cv2.COLOR_RGB2BGR), manual=True)

else:  # ä¸Šä¼ è§†é¢‘
    uploaded = st.file_uploader("ä¸Šä¼ è§†é¢‘", type=["mp4", "avi", "mov"])
    if uploaded:
        tfile = tempfile.NamedTemporaryFile(delete=False)
        tfile.write(uploaded.read())
        cap = cv2.VideoCapture(tfile.name)
        st.session_state.video_playing = True
        while st.session_state.video_playing:
            ret, frame = cap.read()
            if not ret:
                break
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            defects = yolo_detect(frame, conf_th)
            vis = draw_results(frame.copy(), defects)
            orig_disp.image(frame, channels="RGB")
            det_disp.image(vis, channels="RGB")
            if auto_save:
                save_result(defects, cv2.cvtColor(vis, cv2.COLOR_RGB2BGR))
            if manual_save and st.session_state.space_pressed == "space_pressed":
                save_result(defects, cv2.cvtColor(vis, cv2.COLOR_RGB2BGR), manual=True)
                st.session_state.space_pressed = None
            time.sleep(0.03)
        cap.release()

# æœ€åå±•ç¤ºæ£€æµ‹å†å²
with st.expander("æ£€æµ‹å†å²"):
    if st.session_state.detection_history:
        df = pd.DataFrame(st.session_state.detection_history)
        st.dataframe(df)
    else:
        st.info("æš‚æ— å†å²è®°å½•")
